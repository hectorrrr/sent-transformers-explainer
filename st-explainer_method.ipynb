{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Transformers Explainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to clarify our own implementation of a 'Sentence Transformers' explainability method. \n",
    "For this we will be basing our work in two main sources:\n",
    "* The 'Integrated Gradients' method, a numerical method that stablish a cuantitative relation between inputs and outputs in Deep learning models. For further context refer to the [original paper](https://arxiv.org/pdf/1703.01365)\n",
    "\n",
    "* Captum, an Open source python library that implements multiple 'explainability' methods, on top of Pytorch models. Specially, we take as reference the [Bert Tutorial](https://captum.ai/tutorials/Bert_SQUAD_Interpret)\n",
    "\n",
    "\n",
    "\n",
    "We are going to do now a small mathematical review of the Integrated Gradients method, that will be necessary afterwards to understand every component of our method:\n",
    "\n",
    "As pointed in the Paper itself, this method 'aims' to  *Attribute the output (prediction) of a network to it's inputs*. This means that tries to 'decompose' the predicted value of the model in terms of the Input variables. This would be equivalent that each coefficient in a Linear Regression model. In this case, the idea behind the method is to get those 'Attributions', using a reference point in the space of inputs, called baseline, and compute a *path integral of the gradients along a straightline from the baseline x' to the input x* [(1)](https://arxiv.org/pdf/1703.01365):\n",
    "\n",
    "$$\n",
    "\\text{IntegratedGrads}(x) := (x - x') \\times \\int_{\\alpha=0}^{1} \\frac{\\partial F(x' + \\alpha \\times (x - x'))}{\\partial x_i} d\\alpha\n",
    "$$\n",
    "\n",
    "\n",
    "One of the most relevant and important consequences of the Integrated Gradients, is that, due to the properties of Path Integrals, the sum of the Attrobutions of each of the inputs have to correspond to the difference of the output between the chosen Baseline and the real input.\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n} \\text{IntegratedGrads}_i(x) = F(x) - F(x')\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Therefore, we can see that the Baseline that we choose is really influencing the method. Ideally we should pick one that satisfies F(x')~0, but we will see later that for most 'Sentence Transformers' models, this is not feasible.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define our model\n",
    "\n",
    "The first step will be to define our model. Even if we are using sentence transformers model, we will be using it throught their Pytorch backbone, because we need to be able to use the 'tokens' as inputs directly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import LayerIntegratedGradients\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Load a pre-trained sentence-transformers model\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "model.to(device)\n",
    "# model.eval()\n",
    "# model.zero_grad()\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to define a 'predict' function, that is going to generate the output of our model, and takes as input the exact inputs of the model. Therefore this inputs should be the tokens of our sentences, because those are the real inputs of our model and not a 'sentence'. This predict function will be used afterwards by the captum method to get the numerical gradients of the model transformation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]  # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "def predict(input_ids, token_type_ids=None, attention_mask=None):\n",
    "    \"\"\"\n",
    "    Predicts the similarity between pairs of sentences.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_ids: A tensor of shape [number_of_pairs, 2, seq_len] containing pairs of sentences.\n",
    "    - token_type_ids: Optional token type ids (same shape as input_ids).\n",
    "    - attention_mask: Optional attention mask (same shape as input_ids).\n",
    "    \n",
    "    Returns:\n",
    "    - similarities: A tensor of shape [number_of_pairs, 1] containing similarity scores for each pair.\n",
    "    \"\"\"\n",
    "    \n",
    "    num_pairs = input_ids.shape[0]  # Number of sentence pairs\n",
    "    seq_len = input_ids.shape[-1]   # Sequence length\n",
    "    \n",
    "    # Flatten the input for batch processing\n",
    "    input_ids = input_ids.view(num_pairs * 2, seq_len)\n",
    "    \n",
    "    if token_type_ids is not None:\n",
    "        token_type_ids = token_type_ids.view(num_pairs * 2, seq_len)\n",
    "    if attention_mask is not None:\n",
    "        attention_mask = attention_mask.view(num_pairs * 2, seq_len)\n",
    "\n",
    "    # Step 1: Compute sentence embeddings for all sentences in the batch\n",
    "    model_output = model(input_ids=input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # Perform pooling to get embeddings\n",
    "    sentence_embeddings = mean_pooling(model_output, attention_mask)\n",
    "\n",
    "    # Normalize embeddings\n",
    "    sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "    # Step 2: Reshape embeddings back into pairs (number of pairs, 2, embedding_dim)\n",
    "    sentence_embeddings = sentence_embeddings.view(num_pairs, 2, -1)\n",
    "\n",
    "    # Step 3: Compute cosine similarity for each pair\n",
    "    similarities = torch.nn.functional.cosine_similarity(sentence_embeddings[:, 0, :], sentence_embeddings[:, 1, :], dim=1)\n",
    "\n",
    "    # Return similarity scores in shape [number_of_pairs, 1]\n",
    "    return similarities.view(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_trans_pos_forward_func(input_ids,token_type_ids,attention_mask):\n",
    "    print(\"Method calling the predict function for ids\",input_ids.shape)\n",
    "    pred = predict(input_ids,token_type_ids,attention_mask)\n",
    "    print(\"Value predicted--->\", pred)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 16])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example input tensor (batch_size=2, 2 pairs per batch, seq_length=16)\n",
    "input_ids = torch.tensor(\n",
    "    [\n",
    "        [\n",
    "        [  101,  1045,  2293,  5983,  2003,  2026,  5440,  7570, 10322,  2666,  1012,   102,     0,     0,     0,     0],\n",
    "        [  101,  1045,  2293,  5983,  2003,  2026,  5440,  7570, 10322,  2600,  1012,   102,  0,     0,     0,     0]\n",
    "        ],\n",
    "        [\n",
    "        [  101,  1045,  2293,  5983,  2003,  2026,  5440,  7570, 10322,  2666,  1012,   102,     0,     0,     0,     0],\n",
    "        [  101,  1045,  2293,  5983,  2003,  2026,  5440,  7570, 10322,  2600,  1012,   102,  0,     0,     0,     0]\n",
    "        ]\n",
    "    \n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarities: tensor([[0.9198],\n",
      "        [0.9198]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming token_type_ids and attention_mask are similar in structure\n",
    "token_type_ids = torch.zeros_like(input_ids)  # For simplicity, assume all zeros\n",
    "attention_mask = (input_ids != 0).long()  # Attention mask where 0s are padding\n",
    "\n",
    "# Assuming `model` and `mean_pooling` are defined, and predict function is implemented\n",
    "cosine_similarities = predict(input_ids, token_type_ids, attention_mask)\n",
    "\n",
    "# Print the output\n",
    "print(\"Cosine similarities:\", cosine_similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking new things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_token_id = tokenizer.pad_token_id # A token used for generating token reference\n",
    "sep_token_id = tokenizer.sep_token_id # A token used as a separator between question and text and it is also added to the end of the text.\n",
    "cls_token_id = tokenizer.cls_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: tensor([[[ 101, 1045, 2293, 3698, 4083, 1012,  102],\n",
      "         [ 101, 3698, 4083, 2003, 2307,  999,  102]]])\n",
      "Reference Input IDs: tensor([[[0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0]]])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "captum_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
