{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Transformers Explainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to clarify our own implementation of a 'Sentence Transformers' explainability method. It would be focused in a task of 'Sentence similarity' using this models.\n",
    "For this we will be basing our work in two main sources:\n",
    "* The 'Integrated Gradients' method, a numerical method that stablish a cuantitative relation between inputs and outputs in Deep learning models. For further context refer to the [original paper](https://arxiv.org/pdf/1703.01365)\n",
    "\n",
    "* Captum, an Open source python library that implements multiple 'explainability' methods, on top of Pytorch models. Specially, we take as reference the [Bert Tutorial](https://captum.ai/tutorials/Bert_SQUAD_Interpret)\n",
    "\n",
    "\n",
    "\n",
    "We are going to do now a small mathematical review of the Integrated Gradients method, that will be necessary afterwards to understand every component of our method:\n",
    "\n",
    "As pointed in the Paper itself, this method 'aims' to  *Attribute the output (prediction) of a network to it's inputs*. This means that tries to 'decompose' the predicted value of the model in terms of the Input variables. This would be equivalent that each coefficient in a Linear Regression model. In this case, the idea behind the method is to get those 'Attributions', using a reference point in the space of inputs, called baseline, and compute a *path integral of the gradients along a straightline from the baseline x' to the input x* [(1)](https://arxiv.org/pdf/1703.01365):\n",
    "\n",
    "$$\n",
    "\\text{IntegratedGrads}(x) := (x - x') \\times \\int_{\\alpha=0}^{1} \\frac{\\partial F(x' + \\alpha \\times (x - x'))}{\\partial x_i} d\\alpha\n",
    "$$\n",
    "\n",
    "\n",
    "One of the most relevant and important consequences of the Integrated Gradients, is that, due to the properties of Path Integrals, the sum of the Attrobutions of each of the inputs have to correspond to the difference of the output between the chosen Baseline and the real input.\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n} \\text{IntegratedGrads}_i(x) = F(x) - F(x')\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Therefore, we can see that the Baseline that we choose is really influencing the method. Ideally we should pick one that satisfies F(x')~0, but we will see later that for most 'Sentence Transformers' models, this is not feasible.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define our model\n",
    "\n",
    "The first step will be to define our model. Even if we are using sentence transformers model, we will be using it throught their Pytorch backbone, because we need to be able to use the 'tokens' as inputs directly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hecto\\OneDrive\\Escritorio\\github_projects\\sent-transformers-explainer\\captum_env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import LayerIntegratedGradients\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "# Set up logging configuration\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Load a pre-trained sentence-transformers model\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "model.to(device)\n",
    "# model.eval()\n",
    "# model.zero_grad()\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to define a 'forward' function, that is going to generate the output of our model, and takes as input the exact inputs of the model. Therefore this inputs should be the tokens of our sentences, because those are the real inputs of our model and not a 'sentence'. This forward function will be used afterwards by the captum method to get the numerical gradients of the model transformation.\n",
    "\n",
    "Even if the tokens are already numerical features, we do know that they don't have a real numerical meaning. Therefore, we will be using LayerIntegratedGradients, that allows to get the 'Attributions' for each of the Inputs/Outputs of a specified layer of the model. In this case we are interested in getting the Attributions of the Embeddings layer, so we can get the relevance of each word (token) based in the Attributions of each dimension of their embeddings.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]  # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "def predict(input_ids, token_type_ids=None, attention_mask=None):\n",
    "    \"\"\"\n",
    "    Predicts the similarity between pairs of sentences.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_ids: A tensor of shape [number_of_pairs, 2, seq_len] containing pairs of sentences.\n",
    "    - token_type_ids: Optional token type ids (same shape as input_ids).\n",
    "    - attention_mask: Optional attention mask (same shape as input_ids).\n",
    "    \n",
    "    Returns:\n",
    "    - similarities: A tensor of shape [number_of_pairs, 1] containing similarity scores for each pair.\n",
    "    \"\"\"\n",
    "    \n",
    "    num_pairs = input_ids.shape[0]\n",
    "    seq_len = input_ids.shape[-1]\n",
    "    \n",
    "    # Flatten the input for batch processing\n",
    "    input_ids = input_ids.view(num_pairs * 2, seq_len)\n",
    "    \n",
    "    if token_type_ids is not None:\n",
    "        token_type_ids = token_type_ids.view(num_pairs * 2, seq_len)\n",
    "    if attention_mask is not None:\n",
    "        attention_mask = attention_mask.view(num_pairs * 2, seq_len)\n",
    "\n",
    "\n",
    "    # First we get the embeddings for all the inputs ids that have been flatten\n",
    "    model_output = model(input_ids=input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\n",
    "    sentence_embeddings = mean_pooling(model_output, attention_mask)\n",
    "    sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "    \n",
    "    # Then we return them to their original shape (n_pairs,n_sentences, length)\n",
    "    sentence_embeddings = sentence_embeddings.view(num_pairs, 2, -1)\n",
    "    similarities = torch.nn.functional.cosine_similarity(sentence_embeddings[:, 0, :], sentence_embeddings[:, 1, :], dim=1)\n",
    "\n",
    "    return similarities.view(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_trans_pos_forward_func(input_ids,token_type_ids,attention_mask):\n",
    "    logging.info(f\"Method calling the predict function with shape {input_ids.shape}\")\n",
    "    pred = predict(input_ids,token_type_ids,attention_mask)\n",
    "    logging.info(f\"Value predicted---> {pred}\")\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input for the function and Baselines\n",
    "\n",
    "Now that we have configured our forward function, we are going to build several functions to get the inputs for this function.\n",
    "This was extracted from the Captum tutorial and slightly modified for our current use case. Let's go over them:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input IDs and Ref Input IDs\n",
    "\n",
    "Before starting with this specific function, let's remind the objective, and introduce some special tokens that will help us with it. As we said in the introduction, the method is trying to 'Attribute' the Output of a model to it's inputs, by calculating a Path integral from a Baseline. As we are using Sentence transformers models there are two inherent problems:\n",
    "\n",
    "* There is no Token that produces a 0 vector embedding.\n",
    "\n",
    "* We are computing similarity between sentences, so we can not use both of them as Baseline, it would lead to a 1 prediction (comparing the same starting point).\n",
    "\n",
    "Regarding the first point, the usual approach is to use the 'pad token' of our tokenizer, used to 'fill in gaps' and homogenize sentences of different dimensions. This is the closest token to an 'empty' one. There are other feasible options that we will see later.\n",
    "\n",
    "For the second problem, we will use a sentence (normally the query of the `phrase that is used to search/trigger similarities in a bigger set) as a static reference, and will see which words/tokens caused that score. Also in the Baseline sentence, we will replace every token with the reference token, except the Sep token, used to indicate when a sentence finishes, and the cls token, that is commonly used to aggregate the sequence representation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_token_id = tokenizer.pad_token_id\n",
    "sep_token_id = tokenizer.sep_token_id\n",
    "cls_token_id = tokenizer.cls_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_input_ref_pair(sentences, ref_token_id=0, process_both=True):\n",
    "    \"\"\"\n",
    "    Construct input_ids and ref_input_ids for a pair of sentences, excluding the first one\n",
    "    if specified.\n",
    "    \n",
    "    Input:\n",
    "    - sentences: A list of 2 sentences.\n",
    "    - ref_token_id: Token to be used as reference.\n",
    "    - process_both: Flag to determine if processing both phrases or just the second\n",
    "    \n",
    "    Output:\n",
    "    - input_ids: Tensor of shape [1, 2, max_length]\n",
    "    - ref_input_ids: Tensor of shape [1, 2, max_length]\n",
    "    \"\"\"\n",
    "\n",
    "    # We could generalize this method to any dimension of pairs of sentences\n",
    "    assert len(sentences) == 2\n",
    "\n",
    "    # Tokenize the pair\n",
    "    encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "    input_ids = encoded_input['input_ids']  # shape: [2, max_length]\n",
    "    \n",
    "    # Create a reference tensor using the ref token\n",
    "    ref_input_ids = torch.full(input_ids.shape, ref_token_id)\n",
    "    \n",
    "    # Reintroduce the classification and sep tokens\n",
    "    for i, input_id_sequence in enumerate(input_ids):\n",
    "        if not process_both and i == 0:  # Skip processing for the first sentence if process_both is False\n",
    "            ref_input_ids[i] = input_id_sequence\n",
    "        else:\n",
    "            ref_input_ids[i, input_id_sequence == cls_token_id] = cls_token_id\n",
    "            ref_input_ids[i, input_id_sequence == sep_token_id] = sep_token_id\n",
    "\n",
    "    # Reshape input_ids and ref_input_ids to add an additional level of depth [1, 2, max_length]\n",
    "    input_ids = input_ids.unsqueeze(0)  # shape: [1, 2, max_length]\n",
    "    ref_input_ids = ref_input_ids.unsqueeze(0)  # shape: [1, 2, max_length]\n",
    "\n",
    "    return input_ids, ref_input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's tokenize a couple of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['What are sentence transformers?', 'A deep learning model that leverages the Transformers arquitecture to generate sentence embeddings and related tasks']\n",
    "\n",
    "input_ids, ref_input_ids = construct_input_ref_pair(sentences, ref_token_id=ref_token_id, process_both=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs Id's----> tensor([[[  101,  2054,  2024,  6251, 19081,  1029,   102,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0],\n",
      "         [  101,  1037,  2784,  4083,  2944,  2008, 21155,  2015,  1996, 19081,\n",
      "          12098, 15549, 26557, 11244,  2000,  9699,  6251,  7861,  8270,  4667,\n",
      "           2015,  1998,  3141,  8518,   102]]])\n",
      "Ref Inputs Id's----> tensor([[[  101,  2054,  2024,  6251, 19081,  1029,   102,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0],\n",
      "         [  101,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,   102]]])\n",
      "Inputs Id's shape----> torch.Size([1, 2, 25])\n"
     ]
    }
   ],
   "source": [
    "print(\"Inputs Id's---->\",input_ids)\n",
    "\n",
    "print(\"Ref Inputs Id's---->\",ref_input_ids)\n",
    "\n",
    "print(\"Inputs Id's shape---->\",input_ids.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inputs ids are nothing more than the tokenized sentences, \n",
    "while the ref inputs idsare the references for our baseline. Is important to notice that our inputs are going to be of the shape [num_of_pairs, 2 (sentences), lenght of sentences], because the input of our model is two sentences that we want to compare.\n",
    "\n",
    "\n",
    "## Token Type Id's\n",
    "\n",
    "In our use case as we are using individual functions, our token type IDs is just a tensor with all 0's and the same shape of the input id's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_token_type_ids(input_ids):\n",
    "    # Assume no token type differentiation if not needed\n",
    "    token_type_ids = torch.zeros_like(input_ids)\n",
    "    ref_token_type_ids = torch.zeros_like(input_ids)\n",
    "    \n",
    "    return token_type_ids, ref_token_type_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_type_ids, ref_token_type_ids = construct_token_type_ids(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token type ids---> tensor([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0]]])\n",
      "Ref Token type ids---> tensor([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0]]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token type ids--->\",token_type_ids)\n",
    "\n",
    "print(\"Ref Token type ids--->\",ref_token_type_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask token Id's\n",
    "\n",
    "Lastly, we need to provide the mask token ID's as our input. This is specifying whether a 'Input token id' should be taken into consideration by the model. It assigns 0's only to the pad token positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_attention_mask(input_ids):\n",
    "    return (input_ids != tokenizer.pad_token_id).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Mask---> tensor([[[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1]]])\n"
     ]
    }
   ],
   "source": [
    "attention_mask = construct_attention_mask(input_ids)\n",
    "\n",
    "\n",
    "print(\"Attention Mask--->\",attention_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have every input that our forward function requires for our sentences, as well as the Ref Inputs, we can define our Attributions method, but first let's test our it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-05 20:33:41,603 - INFO - Method calling the predict function with shape torch.Size([1, 2, 25])\n",
      "2024-10-05 20:33:41,694 - INFO - Value predicted---> tensor([[0.5704]], grad_fn=<ViewBackward0>)\n",
      "2024-10-05 20:33:41,699 - INFO - Method calling the predict function with shape torch.Size([1, 2, 25])\n",
      "2024-10-05 20:33:41,723 - INFO - Value predicted---> tensor([[0.0650]], grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarities: tensor([[0.5704]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Assuming `model` and `mean_pooling` are defined, and predict function is implemented\n",
    "cosine_similarities = sent_trans_pos_forward_func(input_ids, token_type_ids, attention_mask)\n",
    "\n",
    "# Print the output\n",
    "print(\"Cosine similarities:\", cosine_similarities)\n",
    "\n",
    "baseline_cos_similarities = sent_trans_pos_forward_func(ref_input_ids, token_type_ids, attention_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrated Gradients\n",
    "\n",
    "Let's break down the different arguments:\n",
    "\n",
    "* sent_trans_pos_forward_func: Forward function that is going to be used to calculate the gradients.\n",
    "\n",
    "* model.embeddings: Layer with respect to whose outputs we are going to calculate the allocations\n",
    "\n",
    "* Inputs_ids: The real input tokens\n",
    "\n",
    "* Baselines: The inicial point (neutral) from which the path integrals will start\n",
    "\n",
    "* n_steps: Steps taken to calculate the integral as a numerical approximation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-05 20:01:41,677 - INFO - Method calling the predict function with shape torch.Size([1, 2, 25])\n",
      "2024-10-05 20:01:41,710 - INFO - Value predicted---> tensor([[0.5704]])\n",
      "2024-10-05 20:01:41,714 - INFO - Method calling the predict function with shape torch.Size([1, 2, 25])\n",
      "2024-10-05 20:01:41,736 - INFO - Value predicted---> tensor([[0.0650]])\n",
      "2024-10-05 20:01:41,768 - INFO - Method calling the predict function with shape torch.Size([100, 2, 25])\n",
      "2024-10-05 20:01:42,396 - INFO - Value predicted---> tensor([[0.0649],\n",
      "        [0.0649],\n",
      "        [0.0649],\n",
      "        [0.0649],\n",
      "        [0.0648],\n",
      "        [0.0648],\n",
      "        [0.0647],\n",
      "        [0.0647],\n",
      "        [0.0646],\n",
      "        [0.0645],\n",
      "        [0.0645],\n",
      "        [0.0644],\n",
      "        [0.0643],\n",
      "        [0.0642],\n",
      "        [0.0641],\n",
      "        [0.0640],\n",
      "        [0.0639],\n",
      "        [0.0638],\n",
      "        [0.0638],\n",
      "        [0.0638],\n",
      "        [0.0637],\n",
      "        [0.0638],\n",
      "        [0.0639],\n",
      "        [0.0640],\n",
      "        [0.0642],\n",
      "        [0.0644],\n",
      "        [0.0646],\n",
      "        [0.0648],\n",
      "        [0.0651],\n",
      "        [0.0654],\n",
      "        [0.0657],\n",
      "        [0.0660],\n",
      "        [0.0663],\n",
      "        [0.0667],\n",
      "        [0.0672],\n",
      "        [0.0677],\n",
      "        [0.0683],\n",
      "        [0.0690],\n",
      "        [0.0700],\n",
      "        [0.0714],\n",
      "        [0.0735],\n",
      "        [0.0765],\n",
      "        [0.0809],\n",
      "        [0.0874],\n",
      "        [0.0969],\n",
      "        [0.1105],\n",
      "        [0.1292],\n",
      "        [0.1539],\n",
      "        [0.1846],\n",
      "        [0.2206],\n",
      "        [0.2604],\n",
      "        [0.3019],\n",
      "        [0.3431],\n",
      "        [0.3820],\n",
      "        [0.4173],\n",
      "        [0.4483],\n",
      "        [0.4747],\n",
      "        [0.4963],\n",
      "        [0.5134],\n",
      "        [0.5268],\n",
      "        [0.5373],\n",
      "        [0.5456],\n",
      "        [0.5523],\n",
      "        [0.5577],\n",
      "        [0.5620],\n",
      "        [0.5655],\n",
      "        [0.5683],\n",
      "        [0.5705],\n",
      "        [0.5722],\n",
      "        [0.5734],\n",
      "        [0.5744],\n",
      "        [0.5750],\n",
      "        [0.5755],\n",
      "        [0.5757],\n",
      "        [0.5759],\n",
      "        [0.5759],\n",
      "        [0.5758],\n",
      "        [0.5756],\n",
      "        [0.5754],\n",
      "        [0.5751],\n",
      "        [0.5748],\n",
      "        [0.5745],\n",
      "        [0.5742],\n",
      "        [0.5739],\n",
      "        [0.5735],\n",
      "        [0.5732],\n",
      "        [0.5728],\n",
      "        [0.5725],\n",
      "        [0.5722],\n",
      "        [0.5719],\n",
      "        [0.5717],\n",
      "        [0.5714],\n",
      "        [0.5712],\n",
      "        [0.5710],\n",
      "        [0.5709],\n",
      "        [0.5707],\n",
      "        [0.5706],\n",
      "        [0.5705],\n",
      "        [0.5704],\n",
      "        [0.5704]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "lig = LayerIntegratedGradients(sent_trans_pos_forward_func, model.embeddings)\n",
    "\n",
    "attributions_start = lig.attribute(inputs = input_ids,\n",
    "                                  baselines = ref_input_ids,\n",
    "                                  additional_forward_args=(token_type_ids, attention_mask),\n",
    "                                  n_steps =100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's analyze the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 25, 384])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributions_start.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting by the shape of the attributions, we can see that we have one for each dimension of the embeddings (384) for each token (25) and each sentence (2), as expected. Now if we take a look into the values for each token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [ 0.0000,  0.0232,  0.0210,  0.0397,  0.0149,  0.0105,  0.0105,  0.0087,\n",
       "          0.0079,  0.1634,  0.0075,  0.0087, -0.0011,  0.0111,  0.0013,  0.0146,\n",
       "          0.0956,  0.0078,  0.0110,  0.0098,  0.0116,  0.0044,  0.0172,  0.0061,\n",
       "          0.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributions_start.sum(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We realize that for the first sentence we do not have any value, that is because the baselines and the real inputs are the same, so no attributions is calculated. The same happens with cls and sep tokens. Let's see what happens when we group the attributions of the full sentence:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.5055], dtype=torch.float64)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributions_start.sum(-1).sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributions_start_sum = attributions_start.sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [ 0.0000,  0.0232,  0.0210,  0.0397,  0.0149,  0.0105,  0.0105,  0.0087,\n",
       "          0.0079,  0.1634,  0.0075,  0.0087, -0.0011,  0.0111,  0.0013,  0.0146,\n",
       "          0.0956,  0.0078,  0.0110,  0.0098,  0.0116,  0.0044,  0.0172,  0.0061,\n",
       "          0.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributions_start_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This value, as explained in the introduction, corresponds with the difference between the score of the real input minus the score at the baseline. Therefore, the difference between a score indicating the similarity of our sentence with a 'neutral' sentence, and the real score has been attributed to the different inputs. This is quite powerfull as is telling us which words had more weight in going from a low score to the real prediction of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Visualize the attributions\n",
    "\n",
    "First we need to relate the tokens and positions to the original 'words'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_0 = input_ids[0][0].detach().tolist()\n",
    "indices_1 = input_ids[0][1].detach().tolist()\n",
    "all_tokens_1 = input_ids[0][1].detach().tolist()\n",
    "all_tokens_0 = tokenizer.convert_ids_to_tokens(indices_0)\n",
    "all_tokens_1 = tokenizer.convert_ids_to_tokens(indices_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "from explainability_visual_utils import visualize_text_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's calculate the delta value\n",
    "# Diference in score between baseline and real input\n",
    "diff = cosine_similarities.item() - baseline_cos_similarities.item()\n",
    "\n",
    "## Difference for all token attributions\n",
    "attrib = attributions_start.sum(-1).sum(-1)[1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = diff - attrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_position_vis = viz.VisualizationDataRecord(\n",
    "                        attributions_start_sum[1],\n",
    "                        cosine_similarities[0].item(),\n",
    "                        round(cosine_similarities[0].item()),\n",
    "                        1.0,\n",
    "                        'Positive',\n",
    "                        attributions_start_sum.sum(),       \n",
    "                        all_tokens_1,\n",
    "                        convergence_score = delta )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated rows---> ['<tr><th>True Label</th><th>Predicted Label</th><th>Word Importance</th>', \"<tr><td style='padding: 5px 10px;'>1.0</td><td style='padding: 5px 10px;'>1 (0.57)</td><td><span class='word' style='padding: 2px 4px;'>[CLS]</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.023186476710182372); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.02'>a</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.020956848192606382); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.02'>deep</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.03970290993999699); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.04'>learning</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.01492500990405346); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>model</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.010481872624171619); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>that</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.01048444037070157); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>leverage</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.008731384538624747); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>##s</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.007920896559399523); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>the</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.1634159531774974); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.16'>transformers</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.007509672374730089); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>ar</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.0087303073752889); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>##qui</span> <span class='word' style='background-color: rgba(255, 99, 71, 0.0010608613742509594); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: -0.00'>##tec</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.01113824863319659); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>##ture</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.0013483979769120646); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.00'>to</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.014595061575500355); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>generate</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.09555494046920295); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.10'>sentence</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.007779062579144509); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>em</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.01095412439918609); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>##bed</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.00981391321250376); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>##ding</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.011574445219461897); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>##s</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.0043833197400664865); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.00'>and</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.017212285877334203); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.02'>related</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.00611203572446903); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>tasks</span> <span class='word' style='padding: 2px 4px;'>[SEP]</span></td></tr>\"]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    .word {\n",
       "        cursor: pointer;\n",
       "        padding: 2px 4px;\n",
       "        border-radius: 4px;\n",
       "        position: relative;\n",
       "        display: inline-block;\n",
       "        text-decoration: none; /* Remove any text decoration like line-through */\n",
       "    }\n",
       "    .word:hover::after {\n",
       "        content: attr(data-tooltip);\n",
       "        position: absolute;\n",
       "        top: -35px;\n",
       "        left: 0;\n",
       "        background: #333;\n",
       "        color: #fff;\n",
       "        padding: 5px 10px;\n",
       "        border-radius: 4px;\n",
       "        white-space: nowrap;\n",
       "        z-index: 10;\n",
       "        box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);\n",
       "        font-size: 12px;\n",
       "    }\n",
       "    </style>\n",
       "    <table width='100%' style='border-collapse: collapse; margin-top: 20px;'><tr><th>True Label</th><th>Predicted Label</th><th>Word Importance</th><tr><td style='padding: 5px 10px;'>1.0</td><td style='padding: 5px 10px;'>1 (0.57)</td><td><span class='word' style='padding: 2px 4px;'>[CLS]</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.023186476710182372); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.02'>a</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.020956848192606382); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.02'>deep</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.03970290993999699); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.04'>learning</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.01492500990405346); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>model</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.010481872624171619); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>that</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.01048444037070157); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>leverage</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.008731384538624747); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>##s</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.007920896559399523); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>the</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.1634159531774974); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.16'>transformers</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.007509672374730089); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>ar</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.0087303073752889); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>##qui</span> <span class='word' style='background-color: rgba(255, 99, 71, 0.0010608613742509594); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: -0.00'>##tec</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.01113824863319659); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>##ture</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.0013483979769120646); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.00'>to</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.014595061575500355); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>generate</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.09555494046920295); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.10'>sentence</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.007779062579144509); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>em</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.01095412439918609); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>##bed</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.00981391321250376); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>##ding</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.011574445219461897); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>##s</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.0043833197400664865); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.00'>and</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.017212285877334203); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.02'>related</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.00611203572446903); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>tasks</span> <span class='word' style='padding: 2px 4px;'>[SEP]</span></td></tr></table><div style=\"border-top: 1px solid; margin-top: 20px;             padding-top: 10px; display: inline-block; font-size: 14px;\"><b>Legend: </b><span style=\"display: inline-block; width: 12px; height: 12px;                 border: 1px solid #000; margin-right: 5px; background-color:                 rgba(255, 99, 71, 1)\"></span> Negative  <span style=\"display: inline-block; width: 12px; height: 12px;                 border: 1px solid #000; margin-right: 5px; background-color:                 transparent\"></span> Neutral  <span style=\"display: inline-block; width: 12px; height: 12px;                 border: 1px solid #000; margin-right: 5px; background-color:                 rgba(60, 179, 113, 1)\"></span> Positive  </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    .word {\n",
       "        cursor: pointer;\n",
       "        padding: 2px 4px;\n",
       "        border-radius: 4px;\n",
       "        position: relative;\n",
       "        display: inline-block;\n",
       "        text-decoration: none; /* Remove any text decoration like line-through */\n",
       "    }\n",
       "    .word:hover::after {\n",
       "        content: attr(data-tooltip);\n",
       "        position: absolute;\n",
       "        top: -35px;\n",
       "        left: 0;\n",
       "        background: #333;\n",
       "        color: #fff;\n",
       "        padding: 5px 10px;\n",
       "        border-radius: 4px;\n",
       "        white-space: nowrap;\n",
       "        z-index: 10;\n",
       "        box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);\n",
       "        font-size: 12px;\n",
       "    }\n",
       "    </style>\n",
       "    <table width='100%' style='border-collapse: collapse; margin-top: 20px;'><tr><th>True Label</th><th>Predicted Label</th><th>Word Importance</th><tr><td style='padding: 5px 10px;'>1.0</td><td style='padding: 5px 10px;'>1 (0.57)</td><td><span class='word' style='padding: 2px 4px;'>[CLS]</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.023186476710182372); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.02'>a</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.020956848192606382); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.02'>deep</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.03970290993999699); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.04'>learning</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.01492500990405346); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>model</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.010481872624171619); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>that</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.01048444037070157); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>leverage</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.008731384538624747); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>##s</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.007920896559399523); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>the</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.1634159531774974); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.16'>transformers</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.007509672374730089); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>ar</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.0087303073752889); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>##qui</span> <span class='word' style='background-color: rgba(255, 99, 71, 0.0010608613742509594); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: -0.00'>##tec</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.01113824863319659); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>##ture</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.0013483979769120646); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.00'>to</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.014595061575500355); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>generate</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.09555494046920295); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.10'>sentence</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.007779062579144509); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>em</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.01095412439918609); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>##bed</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.00981391321250376); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>##ding</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.011574445219461897); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>##s</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.0043833197400664865); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.00'>and</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.017212285877334203); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.02'>related</span> <span class='word' style='background-color: rgba(60, 179, 113, 0.00611203572446903); color: white; padding: 2px 4px; border-radius: 4px;' data-tooltip='Importance: 0.01'>tasks</span> <span class='word' style='padding: 2px 4px;'>[SEP]</span></td></tr></table><div style=\"border-top: 1px solid; margin-top: 20px;             padding-top: 10px; display: inline-block; font-size: 14px;\"><b>Legend: </b><span style=\"display: inline-block; width: 12px; height: 12px;                 border: 1px solid #000; margin-right: 5px; background-color:                 rgba(255, 99, 71, 1)\"></span> Negative  <span style=\"display: inline-block; width: 12px; height: 12px;                 border: 1px solid #000; margin-right: 5px; background-color:                 transparent\"></span> Neutral  <span style=\"display: inline-block; width: 12px; height: 12px;                 border: 1px solid #000; margin-right: 5px; background-color:                 rgba(60, 179, 113, 1)\"></span> Positive  </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize_text_v2([first_position_vis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "captum_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
